{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\noona\\anaconda3\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''Example of VAE and AE on MNIST dataset using a CNN.\n",
    "There are three models the encoder, decoder and autoencoder.\n",
    "The encoder generates the latent variables and the \n",
    "decoder can be used to generate MNIST digits by sampling. The VAE\n",
    "restricts the latent vector/variable to be from a Gaussian distribution \n",
    "with mean = 0 and std = 1. This example was adapted fro\n",
    "# Reference\n",
    "[1] Kingma, Diederik P., and Max Welling.\n",
    "\"Auto-Encoding Variational Bayes.\"\n",
    "https://arxiv.org/abs/1312.6114\n",
    "'''\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "# Load the module we need\n",
    "# Note that we are import the Keras backend, which is assumed to be Tensorflow\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, Conv2DTranspose, MaxPooling2D\n",
    "from tensorflow.keras.layers import UpSampling2D, Reshape\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adagrad\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "from tensorflow.keras.layers import Lambda\n",
    "from tensorflow.keras.losses import mean_squared_error, binary_crossentropy, mse, KLDivergence\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function samples random points from a distribution\n",
    "# reparameterization trick\n",
    "# instead of sampling from Q(z|X), sample epsilon = N(0,I)\n",
    "# z = z_mean + sqrt(var) * epsilon\n",
    "def sampling(args):\n",
    "    \"\"\"Reparameterization trick by sampling from an isotropic unit Gaussian.\n",
    "    # Arguments\n",
    "        args (tensor): mean and log of variance of Q(z|X)\n",
    "    # Returns\n",
    "        z (tensor): sampled latent vector\n",
    "    \"\"\"\n",
    "\n",
    "    z_mean, z_log_var = args\n",
    "    batch = K.shape(z_mean)[0]\n",
    "    dim = K.int_shape(z_mean)[1]\n",
    "    # by default, random_normal has mean = 0 and std = 1.0\n",
    "    epsilon = K.random_normal(shape=(batch, dim))\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "\n",
    "def plot_results(models,\n",
    "                 data,\n",
    "                 batch_size=128,\n",
    "                 model_name=\"vae_mnist\"):\n",
    "    \"\"\"Plots labels and MNIST digits as a function of the 2D latent vector\n",
    "    # Arguments\n",
    "        models (tuple): encoder and decoder models\n",
    "        data (tuple): test data and label\n",
    "        batch_size (int): prediction batch size\n",
    "        model_name (string): which model is using this function\n",
    "    \"\"\"\n",
    "\n",
    "    encoder, decoder = models\n",
    "    x_test, y_test = data\n",
    "    os.makedirs(model_name, exist_ok=True)\n",
    "\n",
    "    filename = os.path.join(model_name, \"vae_mean.png\")\n",
    "    # display a 2D plot of the digit classes in the latent subspace\n",
    "    if (model_name == 'vae_mlp'):\n",
    "        z_mean, _, _ = encoder.predict(x_test,\n",
    "                                   batch_size=batch_size)\n",
    "    else:\n",
    "        z_mean = encoder.predict(x_test,batch_size=batch_size)\n",
    "    \n",
    "    plt.figure(figsize=(12, 10))\n",
    "    plt.scatter(z_mean[:, 0], z_mean[:, 1], c=y_test)\n",
    "    plt.colorbar()\n",
    "    plt.xlabel(\"z[0]\")\n",
    "    plt.ylabel(\"z[1]\")\n",
    "    plt.savefig(filename)\n",
    "    plt.show()\n",
    "\n",
    "    filename = os.path.join(model_name, \"digits_over_latent.png\")\n",
    "    # display a 30x30 2D manifold of digits\n",
    "    n = 30\n",
    "    digit_size = 28\n",
    "    figure = np.zeros((digit_size * n, digit_size * n))\n",
    "    # linearly spaced coordinates corresponding to the 2D plot\n",
    "    # of digit classes in the latent space\n",
    "    grid_x = np.linspace(np.amin(z_mean[:,0]), np.amax(z_mean[:,0]), n)\n",
    "    grid_y = np.linspace(np.amin(z_mean[:,1]), np.amax(z_mean[:,1]), n)[::-1]\n",
    "\n",
    "    z_sample = np.zeros((1,5))\n",
    "    z_sample[0,2] = np.mean(z_mean[:,2])\n",
    "    z_sample[0,3] = np.mean(z_mean[:,3])\n",
    "    z_sample[0,4] = np.mean(z_mean[:,4])    \n",
    "    for i, yi in enumerate(grid_y):\n",
    "        for j, xi in enumerate(grid_x):\n",
    "            z_sample[0,0] = xi\n",
    "            z_sample[0,1] = yi\n",
    "            x_decoded = decoder.predict(z_sample)\n",
    "            digit = x_decoded[0].reshape(digit_size, digit_size)\n",
    "            figure[i * digit_size: (i + 1) * digit_size,\n",
    "                   j * digit_size: (j + 1) * digit_size] = digit\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    start_range = digit_size // 2\n",
    "    end_range = (n - 1) * digit_size + start_range + 1\n",
    "    pixel_range = np.arange(start_range, end_range, digit_size)\n",
    "    sample_range_x = np.round(grid_x, 1)\n",
    "    sample_range_y = np.round(grid_y, 1)\n",
    "    plt.xticks(pixel_range, sample_range_x)\n",
    "    plt.yticks(pixel_range, sample_range_y)\n",
    "    plt.xlabel(\"z[0]\")\n",
    "    plt.ylabel(\"z[1]\")\n",
    "    plt.imshow(figure, cmap='Greys_r')\n",
    "    plt.savefig(filename)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 15s 1us/step\n"
     ]
    }
   ],
   "source": [
    "# Load MNIST datasets (training and test)\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "\n",
    "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1)) \n",
    "x_test = np.reshape(x_test, (len(x_test), 28, 28, 1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\noona\\anaconda3\\lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\noona\\anaconda3\\lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Model: \"encoded\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 28, 28, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 14, 14, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 12, 12, 16)        4624      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 6, 6, 16)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 4, 4, 8)           1160      \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 5)                 645       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6749 (26.36 KB)\n",
      "Trainable params: 6749 (26.36 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n",
      "Model: \"decoded\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " latent (InputLayer)         [(None, 5)]               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               768       \n",
      "                                                                 \n",
      " reshape_1 (Reshape)         (None, 4, 4, 8)           0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTr  (None, 6, 6, 16)          1168      \n",
      " anspose)                                                        \n",
      "                                                                 \n",
      " up_sampling2d (UpSampling2  (None, 12, 12, 16)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2D  (None, 14, 14, 32)        4640      \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " up_sampling2d_1 (UpSamplin  (None, 28, 28, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2D  (None, 28, 28, 1)         289       \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6865 (26.82 KB)\n",
      "Trainable params: 6865 (26.82 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n",
      "WARNING:tensorflow:From C:\\Users\\noona\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\noona\\anaconda3\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 28, 28, 1)]          0         []                            \n",
      "                                                                                                  \n",
      " encoded (Functional)        (None, 5)                    6749      ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " decoded (Functional)        (None, 28, 28, 1)            6865      ['encoded[0][0]']             \n",
      "                                                                                                  \n",
      " tf.math.subtract (TFOpLamb  (None, 28, 28, 1)            0         ['input_1[0][0]',             \n",
      " da)                                                                 'decoded[0][0]']             \n",
      "                                                                                                  \n",
      " tf.math.square (TFOpLambda  (None, 28, 28, 1)            0         ['tf.math.subtract[0][0]']    \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.multiply (TFOpLamb  (None, 28, 28, 1)            0         ['tf.math.square[0][0]']      \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.math.reduce_mean (TFOpL  (None, 1)                    0         ['tf.math.multiply[0][0]']    \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " add_loss (AddLoss)          (None, 1)                    0         ['tf.math.reduce_mean[0][0]'] \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13614 (53.18 KB)\n",
      "Trainable params: 13614 (53.18 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the Encoder, inputs are the MNIST 28x28 greyscale images \n",
    "input_img = Input(shape=(28, 28, 1))  \n",
    "\n",
    "x = Conv2D(32, (3, 3), activation='relu',padding='same')(input_img)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Conv2D(16, (3, 3), activation='relu')(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu')(x)\n",
    "x = Reshape((128,))(x)\n",
    "z = Dense(5,activation='linear')(x)    \n",
    "\n",
    "encoded = Model(input_img,z,name='encoded')\n",
    "encoded.summary()\n",
    "plot_model(encoded, to_file='AE_encoded.png', show_shapes=True)            \n",
    "\n",
    "# Latent space is a 5 dimensional vector space\n",
    "\n",
    "# This is the decoder, it take the 5 dim latent vector and generates a 28x28 image\n",
    "lats = Input(shape=(5,),name='latent')\n",
    "x = Dense(128,activation='relu')(lats)\n",
    "x = Reshape((4,4,8))(x)\n",
    "x = Conv2DTranspose(16, (3, 3), activation='relu')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2DTranspose(32, (3, 3), activation='relu')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "rec = Conv2DTranspose(1, (3, 3), activation='relu',padding=\"same\")(x)\n",
    "\n",
    "decoded = Model(lats,rec,name='decoded')\n",
    "decoded.summary()\n",
    "plot_model(decoded, to_file='AE_decoded.png', show_shapes=True)     \n",
    "\n",
    "# The autoencoder takes the image as input encodes it, then decodes it\n",
    "rec = decoded(encoded(input_img))\n",
    "autoencoder = Model(input_img,rec)\n",
    "\n",
    "reconstruction_loss = tf.reduce_mean(1000.0*tf.square(input_img-rec),axis=(1,2))\n",
    "autoencoder.add_loss(reconstruction_loss)\n",
    "autoencoder.compile(optimizer='adadelta')\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "469/469 [==============================] - 14s 27ms/step - loss: 109.0672 - val_loss: 106.6793\n",
      "Epoch 2/100\n",
      "469/469 [==============================] - 17s 37ms/step - loss: 78.5676 - val_loss: 65.1713\n",
      "Epoch 3/100\n",
      "469/469 [==============================] - 16s 35ms/step - loss: 64.0214 - val_loss: 62.7135\n",
      "Epoch 4/100\n",
      "331/469 [====================>.........] - ETA: 4s - loss: 62.2771"
     ]
    }
   ],
   "source": [
    "# Train the model, this can take some time\n",
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=100,\n",
    "                batch_size=128,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))\n",
    "autoencoder.save_weights('ae_mlp_mnist.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show a sample of test images that have been through the autoencoder\n",
    "decoded_imgs = autoencoder.predict(x_test)\n",
    "\n",
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i+1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + n + 1)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the plot_results function to show a latent subspace \n",
    "# Use a grid of latent variables to generate MNIST images\n",
    "batch_size=128\n",
    "plot_results((encoded,decoded),\n",
    "            (x_test,y_test),\n",
    "                 batch_size=batch_size,\n",
    "                 model_name=\"AE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (28,28,1)\n",
    "batch_size = 128\n",
    "latent_dim = 5\n",
    "epochs = 20\n",
    "\n",
    "\n",
    "# VAE model = encoder + decoder\n",
    "# build encoder model\n",
    "inputs = Input(shape=input_shape, name='encoder_input')\n",
    "x = Conv2D(32, (3, 3), activation='relu',padding='same')(inputs)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Conv2D(16, (3, 3), activation='relu')(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu')(x)\n",
    "x = Reshape((128,))(x)\n",
    "z_mean = Dense(latent_dim,activation='linear',name='z_mean')(x)\n",
    "z_log_var = Dense(latent_dim, name='z_log_var',activation='linear')(x)\n",
    "\n",
    "# use reparameterization trick to push the sampling out as input\n",
    "# note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
    "z = Lambda(sampling, output_shape=(latent_dim,), name='z')([z_mean, z_log_var])\n",
    "\n",
    "# instantiate encoder model\n",
    "encoder = Model(inputs, [z_mean, z_log_var, z], name='encoder')\n",
    "encoder.summary()\n",
    "plot_model(encoder, to_file='vae_mlp_encoder.png', show_shapes=True)\n",
    "\n",
    "\n",
    "\n",
    "# build decoder model\n",
    "latent_inputs = Input(shape=(latent_dim,), name='z_sampling')\n",
    "x = Dense(128,activation='relu')(latent_inputs)\n",
    "x = Reshape((4,4,8))(x)\n",
    "x = Conv2DTranspose(16, (3, 3), activation='relu')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2DTranspose(32, (3, 3), activation='relu')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "outputs = Conv2DTranspose(1, (3, 3), activation='relu',padding='same')(x)\n",
    "\n",
    "\n",
    "# instantiate decoder model\n",
    "decoder = Model(latent_inputs, outputs, name='decoder')\n",
    "decoder.summary()\n",
    "plot_model(decoder, to_file='vae_mlp_decoder.png', show_shapes=True)\n",
    "\n",
    "# instantiate VAE model\n",
    "outputs = decoder(encoder(inputs)[2])\n",
    "vae = Model(inputs, outputs, name='vae_mlp')\n",
    "vae.summary()\n",
    "plot_model(vae,to_file='vae_mlp.png',show_shapes=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the new loss function with the reconstruction error and the Kulback-Leibler\n",
    "# divergence\n",
    "\n",
    "reconstruction_loss = tf.reduce_mean(1000.0*tf.square(inputs-outputs),axis=(1,2))\n",
    "z = 1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)\n",
    "kl_loss = tf.reduce_sum(-0.5*z, axis=-1)\n",
    "vae_loss = tf.reduce_mean(reconstruction_loss + kl_loss)\n",
    "vae.add_loss(vae_loss)\n",
    "vae.add_metric(tf.reduce_sum(1000.0*tf.square(inputs-outputs),axis=(1,2)),name='rec_loss',aggregation='mean')\n",
    "vae.add_metric(tf.reduce_sum(-0.5*z, axis=-1),name='kl_loss',aggregation='mean')\n",
    "vae.compile(optimizer='adam')\n",
    "\n",
    "# Train the model\n",
    "vae.fit(x_train,epochs=epochs,batch_size=128)\n",
    "vae.save_weights('vae_mlp_mnist.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show some reconstruction examples from the test set\n",
    "\n",
    "decoded_imgs = vae.predict(x_test)\n",
    "\n",
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i+1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + n + 1)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the latent subspace and generate MNIST images from a grid in latent space\n",
    "plot_results((encoder,decoder),\n",
    "            (x_test,y_test),\n",
    "                 batch_size=batch_size,\n",
    "                 model_name=\"vae_mlp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
